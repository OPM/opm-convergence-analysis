#!/usr/bin/env python3
"""
DBG file reader for extracting Flow simulation parameters.

This module reads OPM Flow DBG files to extract convergence monitoring
parameters, tolerances, and other simulation settings.
"""

import re
from pathlib import Path
from typing import Dict, Any, Optional, Union
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


class DBGReader:
    """
    Reader for OPM Flow DBG files.

    Extracts simulation parameters, especially convergence-related settings,
    from the DBG output files generated by Flow.
    """

    def __init__(self, dbg_path: Union[str, Path]):
        """
        Initialize DBG reader.

        Args:
            dbg_path: Path to the DBG file
        """
        self.dbg_path = Path(dbg_path)
        self.parameters = {}

        if not self.dbg_path.exists():
            raise FileNotFoundError(f"DBG file not found: {dbg_path}")

        # Automatically read parameters on initialization
        self.read_parameters()

    def read_parameters(self) -> Dict[str, Any]:
        """
        Read and parse all parameters from the DBG file.

        Returns:
            Dictionary of parameter name -> value pairs
        """
        self.parameters = {}

        try:
            with open(self.dbg_path, "r", encoding="utf-8", errors="ignore") as f:
                lines_processed = 0
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    lines_processed += 1

                    # Skip empty lines and comments
                    if not line or line.startswith("#"):
                        continue

                    # Look for parameter lines: ParameterName="value" # comment
                    match = re.match(r'(\w+)="([^"]*)"(?:\s*#.*)?$', line)
                    if match:
                        param_name, param_value = match.groups()

                        # Try to convert to appropriate type
                        converted_value = self._convert_value(param_value)
                        self.parameters[param_name] = converted_value

        except Exception as e:
            logger.error(f"Error reading DBG file {self.dbg_path}: {e}")
            raise

        logger.info(f"Read {len(self.parameters)} parameters from {self.dbg_path}")
        return self.parameters

    def _convert_value(self, value_str: str) -> Union[str, int, float, bool]:
        """
        Convert string value to appropriate Python type.

        Args:
            value_str: String value from DBG file

        Returns:
            Converted value (int, float, bool, or str)
        """
        # Try boolean
        if value_str.lower() in ("true", "1"):
            return True
        elif value_str.lower() in ("false", "0"):
            return False

        # Try integer
        try:
            if "." not in value_str and "e" not in value_str.lower():
                return int(value_str)
        except ValueError:
            pass

        # Try float
        try:
            return float(value_str)
        except ValueError:
            pass

        # Return as string
        return value_str

    def get_convergence_parameters(self) -> Dict[str, Any]:
        """
        Extract convergence-related parameters.

        Returns:
            Dictionary with convergence parameters in standardized format
        """
        if not self.parameters:
            self.read_parameters()

        # Map DBG parameter names to our standardized names - only include what exists
        convergence_params = {}

        # Only add parameters that actually exist in the DBG file
        if "ToleranceCnv" in self.parameters:
            convergence_params["cnv_tolerance"] = self.parameters["ToleranceCnv"]
        if "ToleranceMb" in self.parameters:
            convergence_params["mb_tolerance"] = self.parameters["ToleranceMb"]
        if "ToleranceCnvRelaxed" in self.parameters:
            convergence_params["cnv_tolerance_relaxed"] = self.parameters[
                "ToleranceCnvRelaxed"
            ]
        if "ToleranceMbRelaxed" in self.parameters:
            convergence_params["mb_tolerance_relaxed"] = self.parameters[
                "ToleranceMbRelaxed"
            ]
        if "ConvergenceMonitoringCutOff" in self.parameters:
            convergence_params["monitoring_cutoff"] = self.parameters[
                "ConvergenceMonitoringCutOff"
            ]
        if "ConvergenceMonitoringDecayFactor" in self.parameters:
            convergence_params["monitoring_decay_factor"] = self.parameters[
                "ConvergenceMonitoringDecayFactor"
            ]
        if "ConvergenceMonitoring" in self.parameters:
            convergence_params["monitoring_enabled"] = self.parameters[
                "ConvergenceMonitoring"
            ]
        if "ToleranceCnvEnergy" in self.parameters:
            convergence_params["energy_tolerance"] = self.parameters[
                "ToleranceCnvEnergy"
            ]
        if "ToleranceEnergyBalance" in self.parameters:
            convergence_params["energy_balance_tolerance"] = self.parameters[
                "ToleranceEnergyBalance"
            ]
        if "ToleranceWells" in self.parameters:
            convergence_params["well_tolerance"] = self.parameters["ToleranceWells"]
        if "ToleranceWellControl" in self.parameters:
            convergence_params["well_control_tolerance"] = self.parameters[
                "ToleranceWellControl"
            ]

        return convergence_params

    def get_case_info(self) -> Dict[str, Any]:
        """
        Extract case information from the DBG file.

        Returns:
            Dictionary with case metadata
        """
        if not self.parameters:
            self.read_parameters()

        case_info = {
            "deck_filename": self.parameters.get("EclDeckFileName", ""),
            "output_dir": self.parameters.get("OutputDir", ""),
            "flow_version": None,  # Will be extracted from header
            "start_time": None,  # Will be extracted from header
            "machine_name": None,  # Will be extracted from header
        }

        # Extract header information
        try:
            with open(self.dbg_path, "r", encoding="utf-8", errors="ignore") as f:
                for line in f:
                    if "Flow Version" in line:
                        match = re.search(r"Flow Version\s*=\s*([^\(]+)", line)
                        if match:
                            case_info["flow_version"] = match.group(1).strip()

                    elif "Machine name" in line:
                        match = re.search(r"Machine name\s*=\s*([^\(]+)", line)
                        if match:
                            case_info["machine_name"] = match.group(1).strip()

                    elif "Simulation started on" in line:
                        match = re.search(r"Simulation started on (.+)", line)
                        if match:
                            case_info["start_time"] = match.group(1).strip()

                    # Stop reading after finding the parameters section
                    if line.strip().startswith("Parameters used by Flow:"):
                        break

        except Exception as e:
            logger.warning(f"Could not extract header info: {e}")

        return case_info

    def get_initial_date(self) -> Optional[datetime]:
        """
        Extract the initial simulation date from the DBG file.

        Looks for lines like: "Report step  0/247 at day 0/3312, date = 06-Nov-1997"
        or "Report step  0/176 at day 0/5355, date = 01-Jan-2001"

        Returns:
            Initial datetime object or None if not found
        """
        try:
            with open(self.dbg_path, "r", encoding="utf-8", errors="ignore") as f:
                for line in f:
                    # Robust regex pattern that handles different formats
                    # Pattern: "Report step  0/XXX at day 0/XXX, date = DD-MMM-YYYY"
                    match = re.search(
                        r"Report step\s+0/\d+\s+at day\s+0/\d+,\s+date\s*=\s*(\d{1,2}-\w{3}-\d{4})",
                        line,
                    )
                    if match:
                        date_str = match.group(1)
                        try:
                            # Parse date in format "DD-MMM-YYYY" (e.g., "06-Nov-1997", "01-Jan-2001")
                            return datetime.strptime(date_str, "%d-%b-%Y")
                        except ValueError:
                            continue

        except (FileNotFoundError, ValueError, IndexError) as e:
            logger.warning(f"Could not parse initial date from DBG file: {e}")

        return None


def find_case_files(input_path: Union[str, Path]) -> Dict[str, Optional[Path]]:
    """
    Find INFOITER and DBG files from various input types.

    Args:
        input_path: Can be:
            - Path to .INFOITER file
            - Path to .DBG file
            - Path to directory containing these files
            - Path to .DATA file (look in same directory)

    Returns:
        Dictionary with 'infoiter' and 'dbg' file paths (None if not found)
    """
    input_path = Path(input_path)

    result = {"infoiter": None, "dbg": None}

    if input_path.is_file():
        if input_path.suffix.upper() == ".INFOITER":
            result["infoiter"] = input_path
            # Look for DBG file in same directory
            stem = input_path.stem
            dbg_path = input_path.parent / f"{stem}.DBG"
            if dbg_path.exists():
                result["dbg"] = dbg_path

        elif input_path.suffix.upper() == ".DBG":
            result["dbg"] = input_path
            # Look for INFOITER file in same directory
            stem = input_path.stem
            infoiter_path = input_path.parent / f"{stem}.INFOITER"
            if infoiter_path.exists():
                result["infoiter"] = infoiter_path

        elif input_path.suffix.upper() == ".DATA":
            # Look for files with same stem in same directory
            stem = input_path.stem
            infoiter_path = input_path.parent / f"{stem}.INFOITER"
            dbg_path = input_path.parent / f"{stem}.DBG"

            if infoiter_path.exists():
                result["infoiter"] = infoiter_path
            if dbg_path.exists():
                result["dbg"] = dbg_path

    elif input_path.is_dir():
        # Search for .INFOITER and .DBG files in directory
        infoiter_files = list(input_path.glob("*.INFOITER"))
        dbg_files = list(input_path.glob("*.DBG"))

        if infoiter_files:
            result["infoiter"] = infoiter_files[0]  # Take first one found
        if dbg_files:
            result["dbg"] = dbg_files[0]  # Take first one found

    return result


def load_case_data(input_path: Union[str, Path]) -> Dict[str, Any]:
    """
    Load case data from flexible input path.

    Args:
        input_path: Path to case files or directory

    Returns:
        Dictionary with loaded data and parameters
    """
    import opm_convergence_analysis as oca

    files = find_case_files(input_path)

    result = {
        "data": None,
        "convergence_params": {},
        "case_info": {},
        "files_found": files,
    }

    # Load INFOITER data if available
    if files["infoiter"]:
        try:
            result["data"] = oca.load_infoiter(str(files["infoiter"]))
            logger.info(f"Loaded INFOITER data from {files['infoiter']}")
        except Exception as e:
            logger.error(f"Failed to load INFOITER file: {e}")

    # Load DBG parameters if available
    if files["dbg"]:
        try:
            dbg_reader = DBGReader(files["dbg"])
            result["convergence_params"] = dbg_reader.get_convergence_parameters()
            result["case_info"] = dbg_reader.get_case_info()
            logger.info(f"Loaded parameters from {files['dbg']}")
        except Exception as e:
            logger.error(f"Failed to load DBG file: {e}")

    return result
